dataset,version,metric,mode,checkpoint-38820_hf
lukaemon_mmlu_college_biology,0eddf6,accuracy,ppl,41.67
lukaemon_mmlu_college_chemistry,9e2300,accuracy,ppl,39.00
lukaemon_mmlu_college_computer_science,5a1625,accuracy,ppl,40.00
lukaemon_mmlu_college_mathematics,13e9be,accuracy,ppl,30.00
lukaemon_mmlu_college_physics,f05705,accuracy,ppl,32.35
lukaemon_mmlu_electrical_engineering,87e5d9,accuracy,ppl,56.55
lukaemon_mmlu_astronomy,69352a,accuracy,ppl,49.34
lukaemon_mmlu_anatomy,a367fc,accuracy,ppl,40.00
lukaemon_mmlu_abstract_algebra,45f14f,accuracy,ppl,37.00
lukaemon_mmlu_machine_learning,16eb9e,accuracy,ppl,35.71
lukaemon_mmlu_clinical_knowledge,b9517f,accuracy,ppl,53.58
lukaemon_mmlu_global_facts,45ca5d,accuracy,ppl,30.00
lukaemon_mmlu_management,f1f94e,accuracy,ppl,64.08
lukaemon_mmlu_nutrition,e8c66b,accuracy,ppl,54.90
lukaemon_mmlu_marketing,6b54fd,accuracy,ppl,73.08
lukaemon_mmlu_professional_accounting,aa502e,accuracy,ppl,37.23
lukaemon_mmlu_high_school_geography,c5312c,accuracy,ppl,55.56
lukaemon_mmlu_international_law,c502b5,accuracy,ppl,68.60
lukaemon_mmlu_moral_scenarios,9dab41,accuracy,ppl,23.80
lukaemon_mmlu_computer_security,557e7e,accuracy,ppl,60.00
lukaemon_mmlu_high_school_microeconomics,9405bf,accuracy,ppl,44.12
lukaemon_mmlu_professional_law,f36e47,accuracy,ppl,34.55
lukaemon_mmlu_medical_genetics,038ad3,accuracy,ppl,52.00
lukaemon_mmlu_professional_psychology,429c8f,accuracy,ppl,43.46
lukaemon_mmlu_jurisprudence,ae7f17,accuracy,ppl,54.63
lukaemon_mmlu_world_religions,904875,accuracy,ppl,48.54
lukaemon_mmlu_philosophy,c9014a,accuracy,ppl,48.23
lukaemon_mmlu_virology,611723,accuracy,ppl,40.36
lukaemon_mmlu_high_school_chemistry,a25dca,accuracy,ppl,41.38
lukaemon_mmlu_public_relations,02be4e,accuracy,ppl,50.91
lukaemon_mmlu_high_school_macroeconomics,267c80,accuracy,ppl,41.28
lukaemon_mmlu_human_sexuality,9a9941,accuracy,ppl,52.67
lukaemon_mmlu_elementary_mathematics,197da6,accuracy,ppl,37.83
lukaemon_mmlu_high_school_physics,777e6e,accuracy,ppl,33.11
lukaemon_mmlu_high_school_computer_science,1bae4a,accuracy,ppl,52.00
lukaemon_mmlu_high_school_european_history,ad843a,accuracy,ppl,54.55
lukaemon_mmlu_business_ethics,83933d,accuracy,ppl,45.00
lukaemon_mmlu_moral_disputes,2a78ed,accuracy,ppl,50.00
lukaemon_mmlu_high_school_statistics,c6e690,accuracy,ppl,37.96
lukaemon_mmlu_miscellaneous,ab0a88,accuracy,ppl,52.36
lukaemon_mmlu_formal_logic,fa56ca,accuracy,ppl,33.33
lukaemon_mmlu_high_school_government_and_politics,813526,accuracy,ppl,56.99
lukaemon_mmlu_prehistory,017963,accuracy,ppl,46.60
lukaemon_mmlu_security_studies,d60130,accuracy,ppl,57.96
lukaemon_mmlu_high_school_biology,6f158a,accuracy,ppl,51.61
lukaemon_mmlu_logical_fallacies,03a488,accuracy,ppl,45.40
lukaemon_mmlu_high_school_world_history,7d5f06,accuracy,ppl,57.81
lukaemon_mmlu_professional_medicine,cdcce1,accuracy,ppl,42.65
lukaemon_mmlu_high_school_mathematics,eef511,accuracy,ppl,33.70
lukaemon_mmlu_college_medicine,21a6fb,accuracy,ppl,53.76
lukaemon_mmlu_high_school_us_history,e73ee8,accuracy,ppl,46.57
lukaemon_mmlu_sociology,423c74,accuracy,ppl,62.19
lukaemon_mmlu_econometrics,efcf91,accuracy,ppl,21.93
lukaemon_mmlu_high_school_psychology,971917,accuracy,ppl,57.98
lukaemon_mmlu_human_aging,406d1b,accuracy,ppl,46.64
lukaemon_mmlu_us_foreign_policy,ac2379,accuracy,ppl,66.00
lukaemon_mmlu_conceptual_physics,7f414f,accuracy,ppl,38.30
hellaswag,47bff9,accuracy - clean,ppl,43.04
hellaswag,47bff9,accuracy - input contaminated,ppl,42.86
hellaswag,47bff9,accuracy - input-and-label contaminated,ppl,44.22
winogrande,c5cf57,accuracy,ll,51.22
ARC-e,a450bd,accuracy,ppl,44.09
ARC-c-test,a450bd,accuracy - clean,ppl,30.81
ARC-c-test,a450bd,accuracy - input contaminated,ppl,37.74
ARC-c-test,a450bd,accuracy - input-and-label contaminated,ppl,34.52
BoolQ,8ce714,accuracy,ppl,62.39
mmlu-humanities,-,naive_average,ppl,47.12
mmlu-stem,-,naive_average,ppl,41.45
mmlu-social-science,-,naive_average,ppl,50.92
mmlu-other,-,naive_average,ppl,49.66
mmlu,-,naive_average,ppl,46.61
mmlu-weighted,-,weighted_average,ppl,44.88

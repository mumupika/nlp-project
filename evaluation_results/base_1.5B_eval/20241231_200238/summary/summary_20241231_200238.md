| dataset | version | metric | mode | Qwen2.5-1.5B_hf |
|----- | ----- | ----- | ----- | -----|
| lukaemon_mmlu_college_biology | 0eddf6 | accuracy | ppl | 68.06 |
| lukaemon_mmlu_college_chemistry | 9e2300 | accuracy | ppl | 45.00 |
| lukaemon_mmlu_college_computer_science | 5a1625 | accuracy | ppl | 52.00 |
| lukaemon_mmlu_college_mathematics | 13e9be | accuracy | ppl | 36.00 |
| lukaemon_mmlu_college_physics | f05705 | accuracy | ppl | 47.06 |
| lukaemon_mmlu_electrical_engineering | 87e5d9 | accuracy | ppl | 67.59 |
| lukaemon_mmlu_astronomy | 69352a | accuracy | ppl | 72.37 |
| lukaemon_mmlu_anatomy | a367fc | accuracy | ppl | 52.59 |
| lukaemon_mmlu_abstract_algebra | 45f14f | accuracy | ppl | 29.00 |
| lukaemon_mmlu_machine_learning | 16eb9e | accuracy | ppl | 40.18 |
| lukaemon_mmlu_clinical_knowledge | b9517f | accuracy | ppl | 64.91 |
| lukaemon_mmlu_global_facts | 45ca5d | accuracy | ppl | 36.00 |
| lukaemon_mmlu_management | f1f94e | accuracy | ppl | 81.55 |
| lukaemon_mmlu_nutrition | e8c66b | accuracy | ppl | 71.24 |
| lukaemon_mmlu_marketing | 6b54fd | accuracy | ppl | 85.47 |
| lukaemon_mmlu_professional_accounting | aa502e | accuracy | ppl | 50.71 |
| lukaemon_mmlu_high_school_geography | c5312c | accuracy | ppl | 81.31 |
| lukaemon_mmlu_international_law | c502b5 | accuracy | ppl | 76.03 |
| lukaemon_mmlu_moral_scenarios | 9dab41 | accuracy | ppl | 28.72 |
| lukaemon_mmlu_computer_security | 557e7e | accuracy | ppl | 80.00 |
| lukaemon_mmlu_high_school_microeconomics | 9405bf | accuracy | ppl | 68.07 |
| lukaemon_mmlu_professional_law | f36e47 | accuracy | ppl | 45.31 |
| lukaemon_mmlu_medical_genetics | 038ad3 | accuracy | ppl | 70.00 |
| lukaemon_mmlu_professional_psychology | 429c8f | accuracy | ppl | 61.27 |
| lukaemon_mmlu_jurisprudence | ae7f17 | accuracy | ppl | 82.41 |
| lukaemon_mmlu_world_religions | 904875 | accuracy | ppl | 81.87 |
| lukaemon_mmlu_philosophy | c9014a | accuracy | ppl | 66.88 |
| lukaemon_mmlu_virology | 611723 | accuracy | ppl | 46.99 |
| lukaemon_mmlu_high_school_chemistry | a25dca | accuracy | ppl | 57.14 |
| lukaemon_mmlu_public_relations | 02be4e | accuracy | ppl | 64.55 |
| lukaemon_mmlu_high_school_macroeconomics | 267c80 | accuracy | ppl | 68.46 |
| lukaemon_mmlu_human_sexuality | 9a9941 | accuracy | ppl | 75.57 |
| lukaemon_mmlu_elementary_mathematics | 197da6 | accuracy | ppl | 50.79 |
| lukaemon_mmlu_high_school_physics | 777e6e | accuracy | ppl | 39.07 |
| lukaemon_mmlu_high_school_computer_science | 1bae4a | accuracy | ppl | 64.00 |
| lukaemon_mmlu_high_school_european_history | ad843a | accuracy | ppl | 77.58 |
| lukaemon_mmlu_business_ethics | 83933d | accuracy | ppl | 72.00 |
| lukaemon_mmlu_moral_disputes | 2a78ed | accuracy | ppl | 68.50 |
| lukaemon_mmlu_high_school_statistics | c6e690 | accuracy | ppl | 53.70 |
| lukaemon_mmlu_miscellaneous | ab0a88 | accuracy | ppl | 73.82 |
| lukaemon_mmlu_formal_logic | fa56ca | accuracy | ppl | 44.44 |
| lukaemon_mmlu_high_school_government_and_politics | 813526 | accuracy | ppl | 76.68 |
| lukaemon_mmlu_prehistory | 017963 | accuracy | ppl | 68.83 |
| lukaemon_mmlu_security_studies | d60130 | accuracy | ppl | 72.65 |
| lukaemon_mmlu_high_school_biology | 6f158a | accuracy | ppl | 75.16 |
| lukaemon_mmlu_logical_fallacies | 03a488 | accuracy | ppl | 72.39 |
| lukaemon_mmlu_high_school_world_history | 7d5f06 | accuracy | ppl | 75.95 |
| lukaemon_mmlu_professional_medicine | cdcce1 | accuracy | ppl | 61.03 |
| lukaemon_mmlu_high_school_mathematics | eef511 | accuracy | ppl | 38.52 |
| lukaemon_mmlu_college_medicine | 21a6fb | accuracy | ppl | 67.05 |
| lukaemon_mmlu_high_school_us_history | e73ee8 | accuracy | ppl | 74.02 |
| lukaemon_mmlu_sociology | 423c74 | accuracy | ppl | 78.61 |
| lukaemon_mmlu_econometrics | efcf91 | accuracy | ppl | 50.00 |
| lukaemon_mmlu_high_school_psychology | 971917 | accuracy | ppl | 81.47 |
| lukaemon_mmlu_human_aging | 406d1b | accuracy | ppl | 65.47 |
| lukaemon_mmlu_us_foreign_policy | ac2379 | accuracy | ppl | 80.00 |
| lukaemon_mmlu_conceptual_physics | 7f414f | accuracy | ppl | 60.00 |
| hellaswag | 47bff9 | accuracy - clean | ppl | 60.34 |
| hellaswag | 47bff9 | accuracy - input contaminated | ppl | 50.00 |
| hellaswag | 47bff9 | accuracy - input-and-label contaminated | ppl | 65.20 |
| winogrande | c5cf57 | accuracy | ll | 58.88 |
| ARC-e | a450bd | accuracy | ppl | 53.79 |
| ARC-c-test | a450bd | accuracy - clean | ppl | 35.50 |
| ARC-c-test | a450bd | accuracy - input contaminated | ppl | 49.06 |
| ARC-c-test | a450bd | accuracy - input-and-label contaminated | ppl | 41.28 |
| BoolQ | 8ce714 | accuracy | ppl | 66.88 |
| mmlu-humanities | - | naive_average | ppl | 66.38 |
| mmlu-stem | - | naive_average | ppl | 54.12 |
| mmlu-social-science | - | naive_average | ppl | 71.55 |
| mmlu-other | - | naive_average | ppl | 65.10 |
| mmlu | - | naive_average | ppl | 63.09 |
| mmlu-weighted | - | weighted_average | ppl | 61.17 |

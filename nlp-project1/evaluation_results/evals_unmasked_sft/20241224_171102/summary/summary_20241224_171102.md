| dataset | version | metric | mode | checkpoint-38820_hf |
|----- | ----- | ----- | ----- | -----|
| lukaemon_mmlu_college_biology | 0eddf6 | accuracy | ppl | 39.58 |
| lukaemon_mmlu_college_chemistry | 9e2300 | accuracy | ppl | 32.00 |
| lukaemon_mmlu_college_computer_science | 5a1625 | accuracy | ppl | 35.00 |
| lukaemon_mmlu_college_mathematics | 13e9be | accuracy | ppl | 32.00 |
| lukaemon_mmlu_college_physics | f05705 | accuracy | ppl | 31.37 |
| lukaemon_mmlu_electrical_engineering | 87e5d9 | accuracy | ppl | 55.17 |
| lukaemon_mmlu_astronomy | 69352a | accuracy | ppl | 44.08 |
| lukaemon_mmlu_anatomy | a367fc | accuracy | ppl | 44.44 |
| lukaemon_mmlu_abstract_algebra | 45f14f | accuracy | ppl | 39.00 |
| lukaemon_mmlu_machine_learning | 16eb9e | accuracy | ppl | 42.86 |
| lukaemon_mmlu_clinical_knowledge | b9517f | accuracy | ppl | 53.96 |
| lukaemon_mmlu_global_facts | 45ca5d | accuracy | ppl | 34.00 |
| lukaemon_mmlu_management | f1f94e | accuracy | ppl | 61.17 |
| lukaemon_mmlu_nutrition | e8c66b | accuracy | ppl | 54.25 |
| lukaemon_mmlu_marketing | 6b54fd | accuracy | ppl | 72.65 |
| lukaemon_mmlu_professional_accounting | aa502e | accuracy | ppl | 34.40 |
| lukaemon_mmlu_high_school_geography | c5312c | accuracy | ppl | 55.05 |
| lukaemon_mmlu_international_law | c502b5 | accuracy | ppl | 65.29 |
| lukaemon_mmlu_moral_scenarios | 9dab41 | accuracy | ppl | 23.69 |
| lukaemon_mmlu_computer_security | 557e7e | accuracy | ppl | 57.00 |
| lukaemon_mmlu_high_school_microeconomics | 9405bf | accuracy | ppl | 44.12 |
| lukaemon_mmlu_professional_law | f36e47 | accuracy | ppl | 34.49 |
| lukaemon_mmlu_medical_genetics | 038ad3 | accuracy | ppl | 46.00 |
| lukaemon_mmlu_professional_psychology | 429c8f | accuracy | ppl | 40.69 |
| lukaemon_mmlu_jurisprudence | ae7f17 | accuracy | ppl | 56.48 |
| lukaemon_mmlu_world_religions | 904875 | accuracy | ppl | 46.20 |
| lukaemon_mmlu_philosophy | c9014a | accuracy | ppl | 45.66 |
| lukaemon_mmlu_virology | 611723 | accuracy | ppl | 42.77 |
| lukaemon_mmlu_high_school_chemistry | a25dca | accuracy | ppl | 44.33 |
| lukaemon_mmlu_public_relations | 02be4e | accuracy | ppl | 53.64 |
| lukaemon_mmlu_high_school_macroeconomics | 267c80 | accuracy | ppl | 38.97 |
| lukaemon_mmlu_human_sexuality | 9a9941 | accuracy | ppl | 51.15 |
| lukaemon_mmlu_elementary_mathematics | 197da6 | accuracy | ppl | 36.51 |
| lukaemon_mmlu_high_school_physics | 777e6e | accuracy | ppl | 32.45 |
| lukaemon_mmlu_high_school_computer_science | 1bae4a | accuracy | ppl | 48.00 |
| lukaemon_mmlu_high_school_european_history | ad843a | accuracy | ppl | 53.33 |
| lukaemon_mmlu_business_ethics | 83933d | accuracy | ppl | 41.00 |
| lukaemon_mmlu_moral_disputes | 2a78ed | accuracy | ppl | 50.58 |
| lukaemon_mmlu_high_school_statistics | c6e690 | accuracy | ppl | 33.33 |
| lukaemon_mmlu_miscellaneous | ab0a88 | accuracy | ppl | 50.32 |
| lukaemon_mmlu_formal_logic | fa56ca | accuracy | ppl | 29.37 |
| lukaemon_mmlu_high_school_government_and_politics | 813526 | accuracy | ppl | 51.30 |
| lukaemon_mmlu_prehistory | 017963 | accuracy | ppl | 47.53 |
| lukaemon_mmlu_security_studies | d60130 | accuracy | ppl | 56.73 |
| lukaemon_mmlu_high_school_biology | 6f158a | accuracy | ppl | 47.10 |
| lukaemon_mmlu_logical_fallacies | 03a488 | accuracy | ppl | 47.85 |
| lukaemon_mmlu_high_school_world_history | 7d5f06 | accuracy | ppl | 55.27 |
| lukaemon_mmlu_professional_medicine | cdcce1 | accuracy | ppl | 35.29 |
| lukaemon_mmlu_high_school_mathematics | eef511 | accuracy | ppl | 31.11 |
| lukaemon_mmlu_college_medicine | 21a6fb | accuracy | ppl | 42.77 |
| lukaemon_mmlu_high_school_us_history | e73ee8 | accuracy | ppl | 47.55 |
| lukaemon_mmlu_sociology | 423c74 | accuracy | ppl | 61.69 |
| lukaemon_mmlu_econometrics | efcf91 | accuracy | ppl | 28.07 |
| lukaemon_mmlu_high_school_psychology | 971917 | accuracy | ppl | 55.96 |
| lukaemon_mmlu_human_aging | 406d1b | accuracy | ppl | 50.67 |
| lukaemon_mmlu_us_foreign_policy | ac2379 | accuracy | ppl | 65.00 |
| lukaemon_mmlu_conceptual_physics | 7f414f | accuracy | ppl | 39.15 |
| hellaswag | 47bff9 | accuracy - clean | ppl | 44.18 |
| hellaswag | 47bff9 | accuracy - input contaminated | ppl | 39.29 |
| hellaswag | 47bff9 | accuracy - input-and-label contaminated | ppl | 46.05 |
| winogrande | c5cf57 | accuracy | ll | 52.33 |
| ARC-e | a450bd | accuracy | ppl | 46.03 |
| ARC-c-test | a450bd | accuracy - clean | ppl | 30.57 |
| ARC-c-test | a450bd | accuracy - input contaminated | ppl | 32.08 |
| ARC-c-test | a450bd | accuracy - input-and-label contaminated | ppl | 35.94 |
| BoolQ | 8ce714 | accuracy | ppl | 58.69 |
| mmlu-humanities | - | naive_average | ppl | 46.41 |
| mmlu-stem | - | naive_average | ppl | 40.24 |
| mmlu-social-science | - | naive_average | ppl | 50.20 |
| mmlu-other | - | naive_average | ppl | 47.63 |
| mmlu | - | naive_average | ppl | 45.43 |
| mmlu-weighted | - | weighted_average | ppl | 43.68 |
